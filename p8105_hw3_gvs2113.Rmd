---
title: "p8105 Homework 3 (UNI:gvs2113)"
output: github_document
author: "Grace Santos"
date: "2023-10-11"
---

```{r}
library(tidyverse)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 
This problem uses a cleaned and reduced version of a dataset entitled: "The Instacart Online Grocery Shopping Dataset 2017" that was accessed on June 24, 2017. As a leading online grocery service, Instacart allows you to shop online from local grocery stores and thus provides us with a dataset involving observations about each grocery order and its user. More specifically, the entire 2017 dataset is an anonymized dataset with over 3 million orders from over 200,000 users. With that, let's see what we can find out by using a more manageable version of the 2017 data... 

```{r}
library(p8105.datasets)
data("instacart")
```

At first glance, the `instacart` data set consists of `r ncol(instacart)` columns and `r nrow(instacart)` observations. The information provided in this data set reveals characteristics of the buyer, their buying habits, the food order and the food products included. There is data included for a total of `r n_distinct(pull(instacart, order_id))` orders placed using the Instacart app. Many of the variables in the dataset hold a collection of identification numbers for the order, the products, the customer,and the department and aisle in which the product is found. It is notable that the all of the orders in dataset we are using belong to the `train` evaluation set, indicated by the `eval_set` column. There is also informative time related data associated with the day of the week and hour of the day each order was placed. Most often, orders were placed on the  `r instacart |> pull(order_dow) |> DescTools::Mode()`th day of the week at `r instacart |> pull(order_hour_of_day) |> DescTools::Mode()`rd hour, which here means Sunday at 2pm. 

Now to answer the questions for the homework assignment: 

How many aisles are there, and which aisles are most items ordered from? 
```{r}
instacart |> 
  group_by(aisle) |> 
  summarize(count = n()) |> nrow()  # total aisles 

instacart |> 
  group_by(aisle) |> 
  summarize(count = n()) |> top_n(3) # most ordered from aisle 
```

Thus, there are 134 total aisles and the top 3 most ordered from aisles are: fresh vegetables, fresh fruits and packages vegetables fruits. 

Plot that shows the number of items ordered in each aisle: 
```{r}
instacart |> 
  group_by(aisle, department) |> 
  summarize(items = n()) |> 
  filter(items > 1000) |> 
  ggplot(aes(x = aisle, y = items)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

A little crowded, but gets the point across. Best viewed in Zoom panel due to number of aisles. 

Table showing three most popular items in specified aisles and include number of orders for each: 
```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  group_by(aisle, product_name) |> 
  summarize(items = n()) |> 
  top_n(3) |> 
  knitr::kable(digits = 1)
```

Table showing mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week: 
```{r}
instacart |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  group_by(product_name, order_dow) |> 
  summarize(mean_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour
  ) |> 
  knitr::kable(digits = 1)
```

## Problem 2 
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

Data Cleaning: 
```{r}
brfss_smart2010 = 
brfss_smart2010 |> 
  janitor::clean_names() |> 
  filter( 
    topic == "Overall Health",
    response %in% c("Poor", "Fair", "Good", "Very Good", "Excellent")) |> 
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE))
```

In 2002 which states were observed at 7 or more locations? 
```{r}
brfss_smart2010 |> 
  filter (year == "2002") |> 
  group_by (locationabbr) |> 
  summarize (locations = n_distinct(locationdesc)) |> 
  filter (locations >= 7) 
```
In 2002, there were 6 states that were observed at 7 or more locations.

In 2010?
```{r}
brfss_smart2010 |> 
  filter (year == "2010") |> 
  group_by (locationabbr) |> 
  summarize (locations = n_distinct(locationdesc)) |> 
  filter (locations >= 7) 
```
In 2010, there were 14 states that were observed at 7 or more locations. 

Construct a dataset limited to "Excellent" responses and then make a "spaghetti" plot of average of `data_value` across locations within a state. 
```{r}
  brfss_smart2010 |> 
  filter(response == "Excellent") |> 
  group_by(year, locationabbr, locationdesc) |> 
  summarize(avg_data_value = mean(data_value)) |> 
  ggplot(aes(x = year, y = avg_data_value, group = locationabbr, color = locationabbr)) + geom_line() + 
  labs (
    title = " Average Data Value across locations within a state for Excellent Responses",
    x = "Year",
    y = "Average Data Value",
    color = "State") 
```

Make a 2-panel plot showing distribution of `data_value` for responses among NY state locations 
```{r}
brfss_smart2010 |> 
  filter(locationabbr == "NY", 
         year %in% c("2006", "2010")) |> 
  ggplot(aes(x = response , y = data_value, group = locationdesc, color = locationdesc)) + geom_line() +
  facet_wrap(. ~ year) + 
  labs( 
    title = "2006 and 2010 Distribtion of Data Values by Responses among NY locations ",
    x = "Respose",
    y = "Data Value",
    color = "Location")
```

## Problem 3 
